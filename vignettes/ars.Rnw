\documentclass[a4paper,11pt]{article}
\usepackage{natbib}
\usepackage{geometry}
\geometry{tmargin=1in,bmargin=1in,lmargin=1in,rmargin=1in}
\usepackage[utf8]{inputenc}
\usepackage{graphicx}
\usepackage{a4wide}
\usepackage[colorlinks,linkcolor=blue,citecolor=red]{hyperref}
\usepackage{float}
\usepackage{parskip}
\usepackage{amsmath}
\usepackage{url}

\title{Introduction to Statistical Computing (STAT 243)
\\ Final Project \\[4mm]
\textbf{R Package:Adaptive Rejection Sampler}}


\author{Dandan Ru, Sargam Jain, Baoyue Liang}

\date{December $11^{th}$ 2018}

\begin{document}

\maketitle

\section{GitHub repository}
The package is available on GitHub under the username
\textbf{sargamjain13}. The direct URL to the package is:
\url{https://github.com/sargam_jain/adaptive_rejection_sampler}.

\section{Introduction}
The R package: adaptive rejection sampler, \texttt{ars}, is an
implementation of adaptive rejection sampling proposed by
\href{https://www.jstor.org/stable/2347565?seq=1#metadata_info_tab_contents}{Gilks et. al
(1992)}. The package conducts rejection sampling for univariate
log-concave probability density functions. The sampling is adaptive as
within the sampling process, the rejection envelope and squeezing
function are updated to converge to the true density function.

The package consists of a primary wrapper function, \texttt{ars()} and
a couple of auxilliary functions used to generate the objects used in
the entire adaptive rejection sampling procedure. The wrapper function
\texttt{ars()} require the users to provide the following arguments:
\begin{itemize}
\item \texttt{M}: Number of points to sample
\item \texttt{lb}: Lower bound for domain of the density function
\item \texttt{ub}: Upper bound for domain of the density function
\item \texttt{f}: Univariate log-concave density function
\item \texttt{mod\_val}: Highest probability density point
\item \texttt{width}: Size of the steps taken around mod\_val to
initialize sampling. 
\end{itemize}

Following is a simple illustration of how the adaptive rejection
sampling is conducted using the \texttt{ars()} package:

<<compile-r-intro, size = "small", eval=FALSE>>=
library(ars)

## Std. Normal function 
dnor <- function(x){
  return((1/(sqrt(2*pi)))*exp(-(x^2)/2))
}

adapt_sample <- ars(M = 10000, lb = -5, ub = 5, f = dnor)
@

The following section describes the approach used to create the
adaptive rejection sampler and explains the role of auxilliary
functions used in the analysis.  

\section{Approach}
We divided the adaptive rejective sampling procedure into four 
stages. Following are the four stages along with the auxilliary
functions that execute each of these stages.  
\begin{itemize}
\item \textbf{Stage I:} Initialization stage (\texttt{initialize\_sample()})
\item \textbf{Stage II:} Sampling stage (\texttt{create\_samples()})
\item \textbf{Stage III:} Squeezing and rejection test (\texttt{sr\_test()})
\item \textbf{Stage IV:} Updation stage (\texttt{update\_z()} and \texttt{update\_hfamily()})
\end{itemize}

Before initiating any of these stages, we first check for concavity,
continuity, and differentiablity of the given density function, and
then the process starts with the initialization process. Once the
algorithm is through Stage I, Stage II to IV are repated until M
sampling points have been generated. The following sub-sections
discuss each of these stages in detail:

\subsection{Stage I: Initialization stage}
We fist check if the user has provided the upper and lower bounds for
$x$ vector. On basis of whether the bounds have been provided, four
possible situations arise, and we initialize the $x$ vector
accordingly:
\begin{itemize}
\item \textbf{Both \texttt{lb} and \texttt{ub} are provided}: We
initialize the first two values of $x$ vector as uniform random
samples between the two bounds.
\item \textbf{Only \texttt{lb} provided}: We define a new upper bound
for $x$, \texttt{uub}. The new bound is defined using the mod\_val. It
is initiated as equal to mod\_val and increased iteratively using the
step width until the derivative of log-density function at
\texttt{uub} becomes greater than or equal to zero. We, then,
initialize the first two values of $x$ vector as uniform random
samples between the \texttt{lb} and \texttt{uub}. 
\item \textbf{Only \texttt{ub} provided}: We define a new lower bound
for $x$, \texttt{llb}. The new bound is defined using the mod\_val. It
is initiated as equal to mod\_val and reduced iteratively using the
step width until the derivative of log-density function at
\texttt{llb} becomes less than or equal to zero. We, then,
initialize the first two values of $x$ vector as uniform random
samples between the \texttt{llb} and \texttt{ub}.
\item \textbf{Both \texttt{lb} and \texttt{ub} are NOT provided}: We
define both, a new lower bound, \texttt{llb}, and a new upper bound
\texttt{uub} for $x$. The new bounds are defined using the
mod\_val. While the \texttt{llb} is initiated as mod\_val - width,
\texttt{uub} is initiated as mod\_val + width. Iteratively,
\texttt{llb} is reduced using the step width until the derivative of
log-density function at \texttt{llb} becomes less than or equal to
zero. Similarly, \texttt{uub} is increased using the step width until
the derivative of log-density function at \texttt{uub} becomes greater
than or equal to zero. We, then, initialize the first two values of
$x$ vector as uniform random samples between the \texttt{llb} and
\texttt{uub}.
\end{itemize}
Once, we have the initial values of the $x$ vector, we define the
log-density and derivative of log-density for the initial values of
the $x$ vector using the function, \texttt{initialize\_hfamily()}. We
refer to these values as the H-family matrix. Using the H-family
matrix, we then, initialize the first three values of the $z$ vector
using \texttt{initialize\_z()}, i.e. the points where tangents to $x$
intersect.

\subsection{Stage II: Sampling stage}
The first step of the sampling stage is to compute the CDF of the
\textit{upper hull} of the envelope function in each interval
i.e. in $[z_i, z_{(i+1)}]$. We initiate a \texttt{for} loop to compute
the CDF and create logic vectors to find $z$ values
that lie in a particular interval. If inside the interval, we cumulate
till the example point, otherwise, if outside the interval, we
cumulate across the entire interval. These steps of sampling stage are
conducted using the function, \texttt{calculate\_scdf()}. The output of
the function is the total CDF, $c$ and cumulated CDF for every
interval. Next, we sample a $M^{2/3}+10$ uniform random samples, and
using these sampled CDF convert the uniform sample to $x$, generating
$M^{2/3}+10$ samples. On average the number of samples generated
should be $M^{2/3}$. The exact value of $M1$ id the authors'
discretion and this can be altered by the user. 

\subsection{Stage III: Squeezing and rejection test}
We conduct the squeezing and rejection test using the function,
\texttt{sr\_test()}. To form the squeezing and rejection tests, we
first compute the u(x) and l(x), using the \texttt{l()} and
\texttt{u()} functions. We then sample a standard uniform random sample, $w$,
and perform the squeezing test. We select the samples that passed the
squeezing test. We then perform the rejection test and select the
first sample that did not pass the squeezing test. The function
returns a list of accepted samples, the first sample that did not pass
the squeezing test, and number of samples accepted.

\subsection{Stage IV: Updation stage}
Using the newly created samples, we now update the H-family using the
function, \texttt{update\_hfamily()}, i.e. we add a new line in the
H-family matrix for the first sample that did not pass the squeezing
test. For the updated H-family matrix, we update the $z$ vector.


\section{Testing framework}
Our testing framework is categorized into tests for primary wrapper
function and tests for auxilliary functions used within the primary
function. For each of these categories, we test if the functions
handle the valid and invalid arguments well. We also check for the
what output objects to expect from the functions.
\subsection{Testing primary wrapper function}
\begin{description}
 \item [Tests for common log-concave functions:] We test if our
 package works for the common log-concave density functions. These
 include: 
 \begin{itemize}
 \item Standard Normal Distribution
 \item Uniform Distribution
 \item Logistic Distribution
 \item Gamma Distribution
 \item Beta Distribution
 \item Exponential Distribution
 \end{itemize}
 \item [Tests for invalid inputs for arguments:] We check for the
 following invalid inputs provided to the primary function:
 \begin{itemize}
 \item If a convex density function is provided as argument
 \item If a non-differentiable function is provided as argument
 \item If a non-continuous function is provided as argument
 \item If the density function is not of the class 'function'
 \item If the lower bound of the domain is greater than the upper bound
 \end{itemize}
 \end{description}
\subsection{Testing for auxilliary functions}
We test the following major auxilliary functions for what to expect as
output with valid and invalid arguments:
\begin{itemize}
\item \texttt{compute\_deriv()}
\item \texttt{initialize\_sample()}
\item \texttt{initialize\_z()}
\item \texttt{create\_sample()}
\item \texttt{calculate\_scdf()}
\item \texttt{update\_z()}
\end{itemize}

\section{Examples: Common log-concave distributions}
This section showcases the working of the \texttt{ars} package for
common log-concave distributions. The black bold line in the graphs
marks the true density function and the blue line marks the density of
observations sampled using adaptive rejection technique. 

\includegraphics[scale = 0.5]{figures/common_density_plots}


\section{Contribution}

The contributions of each of the co-authors for the package are listed
below:
\begin{itemize}
\item Initialization stage: Sargam Jain and Dandan Ru
\item Sampling stage: Baoyue Liang
\item Squeezing and Rejection stage: Baoyue Liang and Dandan Ru
\item Updation stage: Baoyue Liang
\item Testing Framework: Dandan Ru
\item Package Building: Sargam Jain
\item Report writing: Sargam Jain
\end{itemize}
All the co-authors worked together on de-bugging and testing package.

\section{Appendix}

This section presents the R-codes implemented for the primary wrapper
function and the auxillary functions used in the package.

\subsection{Primary wrapper function: \texttt{ars()}}

<<compile-r-append1, size = "small", eval=FALSE>>=
ars <- function(M, lb = -Inf, ub = Inf, f, width = 0.5, mod_val = 0){

    ## Check the class of f: Function
    if(class(f) != "function"){
        stop("Please provide f as a function", call. = FALSE)
    }

    ## Check if lb and ub are both numeric values
    if(class(lb)!="numeric"){
    stop('please provide a numeric value for lb', call. = FALSE)
    }
    if(class(ub)!="numeric"){
    stop('please provide a numeric value for ub', call. = FALSE)
    }

    ## Check if user provide lb<ub
    if(lb >= ub){
        stop("Please provide lb and ub such that lb < ub", call. = FALSE)
    }
    
    ## Generate samples for sanity check: concavity, differentiability, continuity
    if (lb != -Inf && ub != Inf){
        check_vector <- runif(100, lb, ub)
    }
    if (lb == -Inf && ub != Inf){
        neg_epsilon = -(1e+4)
        check_vector <- runif(100, neg_epsilon, ub)
    }
    if (lb != -Inf && ub == Inf){
        pos_epsilon = 1e+4
        check_vector <- runif(100, lb, pos_epsilon)
    }
    if (lb == -Inf && ub == Inf){
        pos_epsilon = 1e+4
        neg_epsilon = -(1e+4)
        check_vector <- runif(100, neg_epsilon, pos_epsilon)
    }
    check_vector <- sort(check_vector)
    epsilon = 1e-6

    ## Condition for continuity
    if(sum(round(compute_log(check_vector + epsilon, f), digits = 6) !=
           round(compute_log(check_vector + epsilon, f), digits = 6)) != 0){
        stop("Density function is either dis-continuous, non-differentiable, or convex.",
    .call = FALSE)
    }

    ## Condition for differentiability
    mode <- round(optimize(f, interval = c(lb, ub))$minimum, 2)
    if(sum(round(compute_deriv(mode,
                               lb = lb,
                               ub = ub, f = f),
                 digits = 4) != round(compute_deriv(x = (mode - 1e-8),
                                                    lb = lb,
                                                    ub = ub, f = f),
                                      digits=4)) != 0){
        stop("Log density function is not differentiable over the domain",
             .call = FALSE)
    }

    ## Condition for concavity
    if(sum(round(diff(compute_deriv(x = check_vector,
    				    lb = lb,
				    ub = ub,
				    f = f)), digits=8) > 1e-4) !=0){
        stop("Log density function is not concave over the domain.",
             .call = FALSE)
    }
    
    ## Special case for Uniform
    if(sum(compute_deriv(x = check_vector,
    			 lb = lb,
			 ub = ub,
			 f = f) != 0) == 0){
        gsample = runif(M, min = lb, max = ub)
        hist(gsample)
        return(gsample)
    }

    ## StageI: Initialize sample
    initialized_sample <- initialize_sample(M, lb, ub, width = 0.5, mod_val = 0, f = f)
    hfamily <- initialized_sample$hfamily
    zvalues <- initialized_sample$zvalues
    
    sample_count = 0
    sample_bag = 0
    
    while(sample_count <= M){

        ## Stage II: Sampling
        samples <- create_samples(M1 = M^(2/3)+10, hfamily, zvalues)
        ## since there would be around M^(1/3), on average
        ## each time we need the squeezing test to accept M^(2/3) samples

        ## Stage III: Squeezing and Rejection
        sr_test_x <- sr_test(samples, hfamily, zvalues, f = f)
        sample_count = sample_count + sr_test_x$count_accept
        sample_bag = c(sample_bag, sr_test_x$x_accept)

        ## Stage IV: Updation
        if (is.na(sr_test_x$x_r) != TRUE){
            hfamily <- update_hfamily(hfamily,x_r = sr_test_x$x_r, lb = lb, ub = ub, f = f)
            zvalues <- update_z(hfamily,lb,ub)
        }
        
    }

    ## Final check for concavity
    if(sum(round(diff(hfamily[,3]),digits=8) > epsilon) !=0){
        stop("Density function is either dis-continuous, non-differentiable, or convex.",
             .call = FALSE)
    }  

    ## Return the M sample in the sample bag
    hist(sample_bag[1:M])
    return(sample_bag[1:M])
}
@

\subsection{Initialization functions: \texttt{initialize\_sample()}}

<<compile-r-append2, size = "small", eval=FALSE>>=

initialize_hfamily <- function(M, lb, ub, h, hprime, x_initial){
  
  ## Initialize  matrix for h family: the columns of matrix are
  ## x, h(x), h'(x)
  ## Filling in the initial values in matrix
    hfamily <- rbind(c(x_initial[1],
                       h(x_initial[1]),
                       hprime(x = x_initial[1],
                              lb = lb,
                              ub = ub)),
                     c(x_initial[2],
                       h(x_initial[2]),
                       hprime(x = x_initial[2],
                              lb = lb,
                              ub = ub)))
    return(hfamily)
}

initialize_z <- function(M, lb, ub, hfamily){
  z<-rep(NA,3)
  ## Initializing a very small integer limiting to 0
  epsilon = 1e-8
  z[1] <- lb
  z[3] <- ub
  if(abs(z[1] - z[3]) < epsilon){
    z[2] <- (hfamily[1, 1] + hfamily[2, 1])/2
  } else {
    z[2] <- ((hfamily[2, 2]-hfamily[1, 2]) -
               (hfamily[2, 1]*hfamily[2, 3]-hfamily[1, 1]*hfamily[1, 3]))/
      (hfamily[1, 3]-hfamily[2, 3])
  }
  if(is.infinite(z[2])){
  z[2] = ( hfamily[1,1] + hfamily[2,1] )/2
  }
  return(z)
}

initialize_sample <- function(M, lb, ub, width = 0.5, mod_val = 0,
                              h = compute_log,
                              hprime = compute_deriv){

    ## Initializing counter index
    count = 0

    ## When both the initial parameter values are initialized by the user
    if(lb != -Inf && ub != Inf){
        x_initial <- sort(runif(2, lb, ub))
        hfamily <- initialize_hfamily(M, lb, ub, h, hprime, x_initial)
        zvalues <- initialize_z(M, lb, ub, hfamily)
    }

    ## When only the upper initial value, x2 is defined by the user
    if(lb == -Inf && ub != Inf){
        ## If the mode of the density is higher than the upper bound
        if(mod_val > ub){
            mod_val <- ub - width
        }
        ## Defining the lower initial value
        llb <- mod_val
        ## Check if h'(x) exists for the newly defined lower bound
        hprime_check <- hprime(x = llb, func = h, lb = lb, ub = ub)
        while(-Inf < hprime_check && hprime_check <= 0 && count <= 100){
            llb <- llb - width
            hprime_check <- compute_deriv(x = llb, func = h, lb = lb, ub = ub)
            count = count + 1
        }
        x_initial <- sort(c(llb, runif(1, llb, ub)))
        hfamily <- initialize_hfamily(M, llb, ub, h, hprime,x_initial)
        zvalues <- initialize_z(M, lb, ub, hfamily)
    }

    ## When only the lower initial value, x1 is defined by the user
    if(lb != -Inf && ub == Inf){
        if(mod_val < lb){
            mod_val <- lb + width
        }
        ## Defining the upper initial value
        uub <- mod_val
        ## Check if h'(x) exists for the newly defined upper bound
        hprime_check <- compute_deriv(x = uub, func = h, lb = lb, ub = ub)
        while(0 <= hprime_check && hprime_check < Inf && count <= 100){
            uub <- uub + width
            hprime_check <- compute_deriv(x = uub, func = h, lb = lb, ub = ub)
            count = count + 1
        }
        x_initial <- sort(c(runif(1, lb, uub),uub))
        hfamily <- initialize_hfamily(M, lb, uub, h, hprime,x_initial)
        zvalues <- initialize_z(M, lb, ub, hfamily)
    }

    ## When both the initial values are not defined by the user
    if(lb == -Inf && ub == Inf){
        llb <- mod_val - width
        uub <- mod_val + width
        ## Check if h'(x) exists for the newly defined bounds
        hprime_check1 <- compute_deriv(x = llb, func = h, lb = lb, ub = ub)
        hprime_check2 <- compute_deriv(x = uub, func = h, lb = lb, ub = ub)
        while(-Inf < hprime_check1 && hprime_check1 <= 0 && count <= 100){
            llb <- llb - width
            hprime_check1 <- compute_deriv(x = llb, func = h, lb = lb, ub = ub)
            count = count + 1
        }
        while(0 <= hprime_check2 && hprime_check2 < Inf && count <= 100){
            uub <- uub + width
            hprime_check2 <- compute_deriv(x = uub, func = h, lb = lb, ub = ub)
            count = count + 1
        }
        x_initial <- c(llb,uub)
        hfamily <- initialize_hfamily(M, llb, uub, h, hprime,x_initial)
        zvalues <- initialize_z(M, lb, ub, hfamily)

        if(count >= 100) {
            stop("mod_val is invalid, initial point cannot be found. Try another mod_val",
                 .call = FALSE)
        }
    }
    return(list("hfamily" = hfamily, "zvalues" = zvalues))
}
@

\subsection{Sampling functions: \texttt{create\_sample()}}

<<compile-r-append3, size = "small", eval=FALSE>>=
calculate_scdf <- function(vals, hfamily, z) {
  
    zlen = length(z)
    cdf = numeric(length(vals))
    c = 0
    
    for(i in 1:(zlen-1)){
        zl = z[i]
        zu = z[i+1]
        xp = hfamily[i,1]
        hp = hfamily[i,2]
        hprimep = hfamily[i,3]
        ## calculate the cumulated density in each interval, parts of
        ## the demonimator of s
        ds = exp(hp)/hprimep * ( exp((zu - xp)*hprimep) - exp((zl - xp)*hprimep) )
        ## get the logic vector, true if val belongs to the
        ## interval
        inside_idx = (zl < vals & vals <= zu)
        ## get the logic vector, true if val is larger than z[i+1]
        greater_idx = vals > zu
        ## if inside interval, only cumulate till the example
        ## point
        cdf[inside_idx] = cdf[inside_idx] + exp(hp)/hprimep *
        (exp((vals[inside_idx] - xp)*hprimep)
	- exp((zl - xp)*hprimep))
        ## if larger than the upper interval, cumulate the whole
        ## interval
        cdf[greater_idx] = cdf[greater_idx] + ds
        ## total CDF
        c = c + ds
    }
    l = list(scdf = cdf/c, c = c )
    return(l)
}

create_samples <- function(M1, hfamily, zvalues, scdf = calculate_scdf){
    zcdf <- calculate_scdf(vals = zvalues, hfamily, z = zvalues)
    zq = zcdf$scdf
    c = zcdf$c
    unif_sample = runif(M1)
    uidx = findInterval(unif_sample, zq)
    intervals_count = length(zq) - 1
    zlow = zvalues[-length(zvalues)]
    res = rep(NA, length(unif_sample))
    
    for(ii in 1:intervals_count){
        ui = unif_sample[uidx == ii]
        if(length(ui) == 0){next}
        
        xp = hfamily[(ii),1]
        hp = hfamily[(ii),2]
        hprimep = hfamily[(ii),3]
        zl = zlow[(ii)]
        ## invert the CDF
        tmp = log((ui-zq[ii]) * hprimep * c / exp(hp) + exp((zl - xp)*hprimep))/hprimep + xp
        ## convert uniform sample to x according to sampled cdf
        res[uidx == ii] = tmp
    }  
    return(res)
}

@

\subsection{Squeezing and Rejection Test functions: \texttt{sr\_test()}}

<<compile-r-append4, size = "small", eval=FALSE>>=

u <- function(x_sample, hfamily,z) {
  
  res = rep(0, length(x_sample))
  interval_idx = findInterval(x_sample, z)
  
  nintervals = length(z) -1
  for(idx in 1:nintervals){
    xi = x_sample[interval_idx == idx]
    ux = hfamily[idx,2] + (xi - hfamily[idx,1]) * hfamily[idx,3]
    res[interval_idx == idx] = ux
  }
  
  return(res)
}

l <- function(x_sample, hfamily){
    res = rep(0, length(x_sample))
    interval_idx = findInterval(x_sample, hfamily[,1])
    
    nintervals = length(hfamily[,1]) - 1
    for(idx in 1:nintervals){
        xi = x_sample[interval_idx == idx]
        xx  = ( (hfamily[idx+1,1] - xi)*hfamily[idx,2] + (xi -
    hfamily[idx,1])*hfamily[idx+1,2] ) /
    ( hfamily[idx+1,1] - hfamily[idx,1])
        res[interval_idx == idx] = xx
    }
    
    res[interval_idx == 0] = -Inf
    res[interval_idx == length(hfamily[,1])]=-Inf
    return(res)
}

sr_test <- function(x_sample, hfamily, zvalues, h = compute_log){
  
    w = runif(length(x_sample))
    count_accept = 0
    x_r = NA
  
    ## perform squeezing test and select the samples that passed the squeezing test
    x_accept = x_sample[exp(l(x_sample,hfamily) - u(x_sample,hfamily,zvalues)) >= w]
    x_reject_s = x_sample[exp(l(x_sample,hfamily) - u(x_sample,hfamily,zvalues)) < w]
    count_accept = count_accept + length(x_accept)
    
    if(length(x_reject_s) != 0){
        ## perform rejection test and select the first sample that did
    	## not passed the squeezing test
        x_r = x_reject_s[1]
        
        if(exp(h(x_reject_s[1]) - u(x_reject_s[1],
			            hfamily,zvalues)) >= w[x_sample==x_r]){
            count_accept = count_accept + 1
            x_accept = c(x_accept,x_r)
        }
    }
    list = list(x_accept = x_accept, x_r = x_r, count_accept = count_accept)
    return(list)
}
@


\subsection{Updation functions: \texttt{update\_hfamily()}, \texttt{update\_z()}}

<<compile-r-append5, size = "small", eval=FALSE>>=
update_hfamily <- function(hfamily, x_r, h = compute_log, hprime = compute_deriv){
  
    newline = cbind(x_r, h(x_r), hprime(x_r, lb = lb, ub = ub))
    hfamily = rbind(hfamily, newline)
    hfamily = hfamily[order(hfamily[ , 1]), ]
    return(hfamily)
}

update_z <- function(hfamily, lb, ub){
    nrow = nrow(hfamily)
    xf0 = hfamily[-nrow, 1]
    xf1 = hfamily[-1, 1]
    hf0 = hfamily[-nrow, 2]
    hf1 = hfamily[-1, 2]
    dhf0 = hfamily[-nrow, 3]
    dhf1 = hfamily[-1, 3]
    
    z = xf0 + (hf0 - hf1 + (xf1 - xf0)*dhf1) / (dhf1 - dhf0)
    inf_idx = is.infinite(z) == TRUE
    z[inf_idx] = ( xf1[inf_idx] + xf0[inf_idx] )/2
    
    z = c(lb, z, ub)
    z = sort(z, decreasing = FALSE)
    return(z)	
}
@



\end{document}


